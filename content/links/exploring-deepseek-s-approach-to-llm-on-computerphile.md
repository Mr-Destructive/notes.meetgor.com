---
title: "Exploring DeepSeek’s approach to LLM on Computerphile"
date: 2026-01-24
draft: false
---

# Exploring DeepSeek’s approach to LLM on Computerphile

**Link:** https://www.youtube.com/watch?v=gY4Z-9QlZ64

## Context

7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h2><ul><li><p><a href="https://www.youtube.com/watch?v=gY4Z-9QlZ64" rel="nofollow ugc noopener">Exploring DeepSeek’s approach to LLM on Computerphile</a><br/><span>This was a great video explaining the key difference on how Deepseek did the LLM game differently, a concept called MoE mixture of experts.

**Source:** techstructive-weekly-27

