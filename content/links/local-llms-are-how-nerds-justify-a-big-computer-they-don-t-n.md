---
title: "Local LLMs are how nerds justify a big computer they don’t need"
date: 2026-01-24
draft: false
---

# Local LLMs are how nerds justify a big computer they don’t need

**Link:** https://world.hey.com/dhh/local-llms-are-how-nerds-now-justify-a-big-computer-they-don-t-need-af2fcb7b

## Context

note to end the year.</p></li><li><p>Vibe coding last year, now this is the trend we are surfing on, this will last decades.</p></li></ul></li><li><p><a href="https://world.hey.com/dhh/local-llms-are-how-nerds-now-justify-a-big-computer-they-don-t-need-af2fcb7b" rel="nofollow ugc noopener">Local LLMs are how nerds justify a big computer they don’t need</a></p><ul><li><p>Curiosity gets the better of them. I have a 8GB device, I can barely run a 1B parameter model. I get frustrated but have nothing to com

**Source:** techstructive-weekly-75

